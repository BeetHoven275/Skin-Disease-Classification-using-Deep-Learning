# =====================================
# FULL FAST TRAINING BLOCK (CPU)
# for ml.c6i.2xlarge
# =====================================

import time
import pandas as pd
from pathlib import Path
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models

# -----------------
# Paths
# -----------------
BASE_DIR = Path("/home/sagemaker-user/skin-ai")
SPLITS_DIR = BASE_DIR / "splits"

TRAIN_CSV = SPLITS_DIR / "train.csv"
VAL_CSV   = SPLITS_DIR / "val.csv"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# -----------------
# Dataset
# -----------------
class SkinDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        self.df = pd.read_csv(csv_file)
        self.transform = transform
        self.labels = sorted(self.df["label"].unique())
        self.label2idx = {l: i for i, l in enumerate(self.labels)}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(row["image_path"]).convert("RGB")
        label = self.label2idx[row["label"]]

        if self.transform:
            img = self.transform(img)

        return img, label

# -----------------
# Config
# -----------------
IMG_SIZE = 224
BATCH_SIZE = 32    
NUM_EPOCHS = 1      
LR = 1e-4

# -----------------
# Transforms
# -----------------
train_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std =[0.229, 0.224, 0.225])
])

val_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std =[0.229, 0.224, 0.225])
])

# -----------------
# Datasets & Loaders
# -----------------
train_ds = SkinDataset(TRAIN_CSV, transform=train_tfms)
val_ds   = SkinDataset(VAL_CSV, transform=val_tfms)

NUM_CLASSES = len(train_ds.labels)
print("Classes:", train_ds.labels)

train_loader = DataLoader(
    train_ds,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=4,
    persistent_workers=True
)

val_loader = DataLoader(
    val_ds,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=4,
    persistent_workers=True
)

# -----------------
# Sanity check
# -----------------
t0 = time.time()
x, y = next(iter(train_loader))
print("Got batch:", x.shape, y.shape, "in", round(time.time() - t0, 2), "sec")

# -----------------
# Model (ResNet18)
# -----------------
model = models.resnet18(pretrained=True)
for p in model.parameters():
    p.requires_grad = False

model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.fc.parameters(), lr=LR)

# -----------------
# Training loop
# -----------------
def train_one_epoch(model, loader, log_every=20):
    model.train()
    total_loss = 0.0

    for step, (imgs, labels) in enumerate(loader, start=1):
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad(set_to_none=True)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        if step % log_every == 0:
            print(f"  step {step}/{len(loader)} - loss {loss.item():.4f}")

    return total_loss / len(loader)

# -----------------
# Run training
# -----------------
for epoch in range(NUM_EPOCHS):
    loss = train_one_epoch(model, train_loader, log_every=20)
    print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] - Train Loss: {loss:.4f}")
